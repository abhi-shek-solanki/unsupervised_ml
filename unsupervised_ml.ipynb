{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"10B2s5af8INkHgIz_7XBjW3iNDbGY7ltx","timestamp":1712829488400}],"collapsed_sections":["iky9q4vBYrdO","F6T5p64dYrdO","y-Ehk30pYrdP","bamQiAODYuh1","QHF8YVU7Yuh3","GwzvFGzlYuh3","qYpmQ266Yuh3","OH-pJp9IphqM","bbFf2-_FphqN","_ouA3fa0phqN","Seke61FWphqN","PIIx-8_IphqN","t27r6nlMphqO","r2jJGEOYphqO","b0JNsNcRphqO","BZR9WyysphqO","jj7wYXLtphqO","eZrbJ2SmphqO","rFu4xreNphqO","YJ55k-q6phqO","gCFgpxoyphqP","OVtJsKN_phqQ","lssrdh5qphqQ","U2RJ9gkRphqQ","1M8mcRywphqQ","tgIPom80phqQ","JMzcOPDDphqR","x-EpHcCOp1ci","X_VqEhTip1ck","8zGJKyg5p1ck","PVzmfK_Ep1ck","n3dbpmDWp1ck","ylSl6qgtp1ck","ZWILFDl5p1ck","M7G43BXep1ck","Ag9LCva-p1cl","E6MkPsBcp1cl","2cELzS2fp1cl","3MPXvC8up1cl","UV0SzAkaZNRQ","YPEH6qLeZNRQ","q29F0dvdveiT","EXh0U9oCveiU","22aHeOlLveiV","g-ATYxFrGrvw","Yfr_Vlr8HBkt","8yEUt7NnHlrM","tEA2Xm5dHt1r","I79__PHVH19G","Ou-I18pAyIpj","fF3858GYyt-u","4_0_7-oCpUZd","hwyV_J3ipUZe","3yB-zSqbpUZe","dEUvejAfpUZe","Fd15vwWVpUZf","bn_IUdTipZyH","49K5P_iCpZyH","Nff-vKELpZyI","kLW572S8pZyI","dWbDXHzopZyI","yLjJCtPM0KBk","xiyOF9F70UgQ","7wuGOrhz0itI","id1riN9m0vUs","578E2V7j08f6","89xtkJwZ18nB","67NQN5KX2AMe","Iwf50b-R2tYG","GMQiZwjn3iu7","WVIkgGqN3qsr","XkPnILGE3zoT","Hlsf0x5436Go","mT9DMSJo4nBL","c49ITxTc407N","OeJFEK0N496M","9ExmJH0g5HBk","cJNqERVU536h","k5UmGsbsOxih","T0VqWOYE6DLQ","qBMux9mC6MCf","-oLEiFgy-5Pf","C74aWNz2AliB","2DejudWSA-a0","pEMng2IbBLp7","rAdphbQ9Bhjc","TNVZ9zx19K6k","nqoHp30x9hH9","rMDnDkt2B6du","yiiVWRdJDDil","1UUpS68QDMuG","kexQrXU-DjzY","T5CmagL3EC8N","BhH2vgX9EjGr","qjKvONjwE8ra","P1XJ9OREExlT","VFOzZv6IFROw","TIqpNgepFxVj","VfCC591jGiD4","OB4l2ZhMeS1U","ArJBuiUVfxKd","4qY1EAkEfxKe","PiV4Ypx8fxKe","TfvqoZmBfxKf","dJ2tPlVmpsJ0","JWYfwnehpsJ1","-jK_YjpMpsJ2","HAih1iBOpsJ2","zVGeBEFhpsJ2","bmKjuQ-FpsJ3","Fze-IPXLpx6K","7AN1z2sKpx6M","9PIHJqyupx6M","_-qAgymDpx6N","Z-hykwinpx6N","h_CCil-SKHpo","cBFFvTBNJzUa","HvGl1hHyA_VK","EyNgTHvd2WFk","KH5McJBi2d8v","iW_Lq9qf2h6X","-Kee-DAl2viO","gCX9965dhzqZ","gIfDvo9L0UH2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Project Name**    -\n","\n"],"metadata":{"id":"vncDsAP0Gaoa"}},{"cell_type":"markdown","source":["##### **Project Type**    -   Unsupervised\n","##### **Contribution**    -  Individual\n","##### **Team Member 1 -**    Abhishek Solanki\n"],"metadata":{"id":"beRrZCGUAJYm"}},{"cell_type":"markdown","source":["## <b> Problem Description </b>\n","\n","InvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n","\n","StockCode: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n","\n","Description: Product (item) name. Nominal.\n","\n","Quantity: The quantities of each product (item) per transaction. Numeric.\n","InvoiceDate: Invice Date and time. Numeric, the day and time when each transaction was generated.\n","\n","UnitPrice: Unit price. Numeric, Product price per unit in sterling.\n","CustomerID: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n","\n","Country: Country name. Nominal, the name of the country where each customer resides."],"metadata":{"id":"F6v_1wHtG2nS"}},{"cell_type":"markdown","source":["# **GitHub Link -**"],"metadata":{"id":"w6K7xa23Elo4"}},{"cell_type":"markdown","source":["Provide your GitHub Link here."],"metadata":{"id":"h1o69JH3Eqqn"}},{"cell_type":"markdown","source":["# **Problem Statement**\n"],"metadata":{"id":"yQaldy8SH6Dl"}},{"cell_type":"markdown","source":["\n","\n","To determine and cluster the customers as per their buying frequency\n","\n","In this project, your task is to identify major customer segments on a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers."],"metadata":{"id":"DpeJGUA3kjGy"}},{"cell_type":"markdown","source":["# **General Guidelines** : -  "],"metadata":{"id":"mDgbUHAGgjLW"}},{"cell_type":"markdown","source":["1.   Well-structured, formatted, and commented code is required.\n","2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n","     \n","     The additional credits will have advantages over other students during Star Student selection.\n","       \n","             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n","                       without a single error logged. ]\n","\n","3.   Each and every logic should have proper comments.\n","4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n","        \n","\n","```\n","# Chart visualization code\n","```\n","            \n","\n","*   Why did you pick the specific chart?\n","*   What is/are the insight(s) found from the chart?\n","* Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n","5. You have to create at least 15 logical & meaningful charts having important insights.\n","\n","\n","[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n","\n","U - Univariate Analysis,\n","\n","B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n","\n","M - Multivariate Analysis\n"," ]\n","\n","\n","\n","\n","\n","6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n","\n","\n","*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n","\n","\n","*   Cross- Validation & Hyperparameter Tuning\n","\n","*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n","\n","*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"ZrxVaUj-hHfC"}},{"cell_type":"markdown","source":["# ***Let's Begin !***"],"metadata":{"id":"O_i_v8NEhb9l"}},{"cell_type":"markdown","source":["## ***1. Know Your Data***"],"metadata":{"id":"HhfV-JJviCcP"}},{"cell_type":"markdown","source":["### Import Libraries"],"metadata":{"id":"Y3lxredqlCYt"}},{"cell_type":"code","source":["# Importing the libraries\n","\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n"],"metadata":{"id":"RJ2v7iR6xX-J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Dataset\n","# I heave directly load it from my file manager without using google drive\n","df = pd.read_csv(\"/content/Online Retail.xlsx - Online Retail.csv\")"],"metadata":{"id":"4CkvbW_SlZ_R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset First View"],"metadata":{"id":"x71ZqKXriCWQ"}},{"cell_type":"code","source":["# Dataset First Look\n","\n","df.head()"],"metadata":{"id":"LWNFOSvLl09H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Rows & Columns count"],"metadata":{"id":"7hBIi_osiCS2"}},{"cell_type":"code","source":["# Dataset Rows & Columns count\n","\n","\n","# computing number of rows\n","rows = len(df.axes[0])\n","\n","# computing number of columns\n","cols = len(df.axes[1])\n","\n","print(\"Number of Rows: \", rows)\n","print(\"Number of Columns: \", cols)"],"metadata":{"id":"Kllu7SJgmLij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Information"],"metadata":{"id":"JlHwYmJAmNHm"}},{"cell_type":"code","source":["# Dataset Info\n","\n","df.info()"],"metadata":{"id":"e9hRXRi6meOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Duplicate Values"],"metadata":{"id":"35m5QtbWiB9F"}},{"cell_type":"code","source":["# Dataset Duplicate Value Count\n","\n","display(df.drop_duplicates())\n","\n","# As you can see now there are 50626 rows and 8 columns are there"],"metadata":{"id":"1sLdpKYkmox0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Missing Values/Null Values"],"metadata":{"id":"PoPl-ycgm1ru"}},{"cell_type":"code","source":["# Missing Values/Null Values Count\n","\n","df.dropna()\n","\n","# also by dropping there are lots pf layers which has been dropped"],"metadata":{"id":"GgHWkxvamxVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing the missing values\n","df['InvoiceNo'] = df['InvoiceNo'].astype('str')\n","df=df[~df['InvoiceNo'].str.contains('C')]\n","df=df[~df['InvoiceNo'].str.contains('A')]"],"metadata":{"id":"3q5wnI3om9sJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","### What did you know about your dataset?"],"metadata":{"id":"H0kj-8xxnORC"}},{"cell_type":"markdown","source":["Answer Here   till nest time"],"metadata":{"id":"gfoNAAC-nUe_"}},{"cell_type":"markdown","source":["## ***2. Understanding Your Variables***"],"metadata":{"id":"nA9Y7ga8ng1Z"}},{"cell_type":"code","source":["\n","# Dataset Columns\n","\n","list(df.columns)"],"metadata":{"id":"j7xfkqrt5Ag5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset Describe\n","\n","df.describe()"],"metadata":{"id":"DnOaZdaE5Q5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data Wrangling Code"],"metadata":{"id":"bKJF3rekwFvQ"}},{"cell_type":"code","source":["# Lets see which products are mostly sold more than 100 times in our data\n","import matplotlib.pyplot as plt\n","\n","# Assuming df is properly defined and contains the necessary data\n","\n","# Filter the data\n","product = df[\"Description\"].value_counts().loc[lambda x: x >= 1500]\n","\n","# Create a pie chart\n","plt.figure(figsize=(10, 8))\n","plt.pie(product.values, labels=product.index, autopct='%1.1f%%', startangle=100)\n","plt.title('Proportions of Products with at Least 100 Occurrences')\n","plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n","plt.show()\n"],"metadata":{"id":"cmXyFMBXBAxw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#lets cheek which customer id is present most in our data\n","\n","customer_id = df[\"CustomerID\"].value_counts().loc[lambda x : x>100]\n","customer_id"],"metadata":{"id":"HL4ACaiW7NCB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What all manipulations have you done and insights you found?"],"metadata":{"id":"MSa1f5Uengrz"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"LbyXE7I1olp8"}},{"cell_type":"markdown","source":["## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"],"metadata":{"id":"GF8Ens_Soomf"}},{"cell_type":"markdown","source":["\n","#### Chart - 1"],"metadata":{"id":"0wOQAZs5pc--"}},{"cell_type":"code","source":["\n","\n","# Assuming df is your DataFrame\n","most_famous_country = df['Country'].value_counts().loc[lambda x: x > 1000]\n","\n","# Convert series to DataFrame for easier plotting\n","most_famous_country_df = most_famous_country.reset_index()\n","most_famous_country_df.columns = ['Country', 'Count']\n","\n","# Create bar plot using Seaborn\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x='Country', y='Count', data=most_famous_country_df)\n","\n","# Add values on top of each bar\n","for index, row in most_famous_country_df.iterrows():\n","    plt.text(index, row['Count']+0.5, row['Count'], color='black', ha=\"center\")\n","\n","# Rotate x-axis labels for better readability\n","plt.xticks(rotation=45)\n","\n","# Add labels and title\n","plt.xlabel('Country')\n","plt.ylabel('Frequency')\n","plt.title('Most Famous Countries (Appearing >50 times)')\n","\n","# Show plot\n","plt.show()\n"],"metadata":{"id":"7v_ESjsspbW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"K5QZ13OEpz2H"}},{"cell_type":"markdown","source":["To check from which country people are importing more stuffs"],"metadata":{"id":"XESiWehPqBRc"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"lQ7QKXXCp7Bj"}},{"cell_type":"markdown","source":["As from the data you can easily say that most of the customers are   from UK . So mostly focus on the UK side customer to gain all the customers"],"metadata":{"id":"C_j1G7yiqdRP"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"448CDAPjqfQr"}},{"cell_type":"markdown","source":["Answer  = Yes from the given data we have to now focus only to top 5 cities"],"metadata":{"id":"3cspy4FjqxJW"}},{"cell_type":"markdown","source":["#### Chart - 2"],"metadata":{"id":"KSlN3yHqYklG"}},{"cell_type":"code","source":["# Chart - 2 visualization code\n","\n","# Now lets check whcih are the customer from Uk that are buying the goods\n","\n","# creating column of only UK countries\n","\n","\n","\n","uk = df[df['Country'] == 'United Kingdom']\n","\n","# Assuming df is your DataFrame and uk is the DataFrame filtered for 'United Kingdom'\n","uk_customers = uk[\"CustomerID\"].value_counts().loc[lambda x: x > 1000]\n","\n","# Convert series to DataFrame for easier plotting\n","uk_customers_df = uk_customers.reset_index()\n","uk_customers_df.columns = ['CustomerID', 'Transaction Count']\n","\n","# Create bar plot using Seaborn\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x='CustomerID', y='Transaction Count', data=uk_customers_df)\n","\n","# Add labels and title\n","plt.xlabel('Customer ID')\n","plt.ylabel('Number of Transactions')\n","plt.title('Number of Transactions by UK Customers (Transactions >150)')\n","\n","# Rotate x-axis labels for better readability (if needed)\n","plt.xticks(rotation=45)\n","\n","# Show plot\n","plt.show()\n"],"metadata":{"id":"R4YgtaqtYklH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"t6dVpIINYklI"}},{"cell_type":"markdown","source":["Answer - To check that from United kingdom on which customer we will spend more time"],"metadata":{"id":"5aaW0BYyYklI"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"ijmpgYnKYklI"}},{"cell_type":"markdown","source":["Answer - Which customer id is present more means which has bought more items"],"metadata":{"id":"PSx9atu2YklI"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"-JiQyfWJYklI"}},{"cell_type":"markdown","source":["Answer Here"],"metadata":{"id":"BcBbebzrYklV"}},{"cell_type":"markdown","source":["#### Chart - 3"],"metadata":{"id":"EM7whBJCYoAo"}},{"cell_type":"code","source":["most_famous_country.head()"],"metadata":{"id":"AUYSfuQNIMka"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"D3wYynAkM5u_"}},{"cell_type":"code","source":["uk_customers = uk[\"CustomerID\"].value_counts().loc[lambda x: x > 1000]\n","uk_customers"],"metadata":{"id":"hcbBu8gJKQev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Chart - 3 visualization code\n","\n","# lets chek which customer has invest more money from above graph\n","\n","df['TotalSpending'] = df.Quantity * df.UnitPrice\n","\n","\n","total_spending_by_customer = df.groupby('CustomerID')['TotalSpending'].sum().loc[lambda x: x > 50000]\n","\n","\n","\n","# Filter total spending by customers who spent more than $3000\n","high_spending_customers = total_spending_by_customer[total_spending_by_customer > 50000]\n","\n","# Create a bar chart\n","plt.figure(figsize=(15, 6))\n","high_spending_customers.plot(kind='bar', color='green')\n","plt.title('Total Spending by High-Spending Customers')\n","plt.xlabel('CustomerID')\n","plt.ylabel('Total Spending ($)')\n","plt.xticks(rotation=45)\n","plt.grid(axis='y', linestyle='--', alpha=0.7)\n","plt.show()\n","\n","\n","\n","\n"],"metadata":{"id":"t6GMdE67YoAp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"fge-S5ZAYoAp"}},{"cell_type":"markdown","source":["Answer -  To check which customer has been paying more rather than just buying things"],"metadata":{"id":"5dBItgRVYoAp"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"85gYPyotYoAp"}},{"cell_type":"markdown","source":["Answer -  How much a customer is generating revenue to us"],"metadata":{"id":"4jstXR6OYoAp"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n"," - Yes it will lead us to know our customer better"],"metadata":{"id":"RoGjAbkUYoAp"}},{"cell_type":"markdown","source":["Answer Here"],"metadata":{"id":"zfJ8IqMcYoAp"}},{"cell_type":"markdown","source":["#### Chart - 4"],"metadata":{"id":"4Of9eVA-YrdM"}},{"cell_type":"code","source":["# Chart - 4 visualization code\n","\n","# now lets check this 3 customer ids that has spends upto more than 10000 dollar means from whcih country they belongs to\n","\n","customer_14646 = df[df[\"CustomerID\"] == 14646.0]\n","print(f\"The Country for customer 14646 is {customer_14646['Country'].unique()}\")\n","\n","customer_17450 = df[df[\"CustomerID\"] == 17450.0]\n","print(f\"The Country for customer 17450 is {customer_17450['Country'].unique()}\")\n","\n","customer_18102 = df[df[\"CustomerID\"] == 18102.0]\n","print(f\"The Country for customer 18102 is {customer_18102['Country'].unique()}\")\n"],"metadata":{"id":"irlUoxc8YrdO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"iky9q4vBYrdO"}},{"cell_type":"markdown","source":["Answer - To chek the country from which we are getting more money"],"metadata":{"id":"aJRCwT6DYrdO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"F6T5p64dYrdO"}},{"cell_type":"markdown","source":["Answer - By this i have found that most of the people that have spent more than 10000 $ are from United Kindgom"],"metadata":{"id":"Xx8WAJvtYrdO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","\n","-  Yes We will try to be in touch with that customer personally or how can we help them to improve our service to satisfy their needs"],"metadata":{"id":"y-Ehk30pYrdP"}},{"cell_type":"markdown","source":["Answer Here"],"metadata":{"id":"jLNxxz7MYrdP"}},{"cell_type":"markdown","source":["#### Chart - 5"],"metadata":{"id":"bamQiAODYuh1"}},{"cell_type":"code","source":["# Chart - 5 visualization code\n","# as there is date column present first convert it to date format from object\n","# Check the first few rows of the 'InvoiceDate' column\n","print(df['InvoiceDate'].head())\n","\n","# Attempt to convert the 'InvoiceDate' column to datetime format\n","df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], format='%m/%d/%y %H:%M', errors='coerce')\n","\n","# Check for any errors during conversion\n","print(df['InvoiceDate'].isnull().sum())\n","\n","# Inspect rows with NaT values to identify and handle any issues\n","print(df[df['InvoiceDate'].isnull()])\n","\n","\n","\n","# adding new time colums to our data\n","\n","df[\"year\"] = df[\"InvoiceDate\"].apply(lambda x: x.year)\n","df[\"month_num\"] = df[\"InvoiceDate\"].apply(lambda x: x.month)\n","df[\"day_num\"] = df[\"InvoiceDate\"].apply(lambda x: x.day)\n","df[\"hour\"] = df[\"InvoiceDate\"].apply(lambda x: x.hour)\n","df[\"minute\"] = df[\"InvoiceDate\"].apply(lambda x: x.minute)\n"],"metadata":{"id":"TIJwrbroYuh3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lets see on which month customer has buy most of the times\n","\n","df['Month']=df['InvoiceDate'].dt.month_name()\n","\n","month_df=df['Month'].value_counts().reset_index()\n","\n","month_df\n","\n","\n","import seaborn\n","\n","\n","# class v / s fare barplot with same colour\n","plt.figure(figsize=(13, 6))\n","sns.barplot(x = 'Month', y = 'count', data = month_df, color = \"red\")\n","\n","# Show the plot\n","plt.show()\n","\n","\n","\n"],"metadata":{"id":"fTBVMmi0hB_c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"QHF8YVU7Yuh3"}},{"cell_type":"markdown","source":["Answer to check the month on which customer is buying"],"metadata":{"id":"dcxuIMRPYuh3"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"GwzvFGzlYuh3"}},{"cell_type":"markdown","source":["Answer - yes it is of december but i have found only december only in the given data"],"metadata":{"id":"uyqkiB8YYuh3"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"qYpmQ266Yuh3"}},{"cell_type":"markdown","source":["Answer Here"],"metadata":{"id":"_WtzZ_hCYuh4"}},{"cell_type":"markdown","source":["#### Chart - 6"],"metadata":{"id":"OH-pJp9IphqM"}},{"cell_type":"code","source":["# Chart - 6 visualization code\n","\n","# Convert 'InvoiceDate' column to datetime format\n","df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"], format=\"%m/%d/%y %H:%M\")\n","\n","# Extract day from 'InvoiceDate' and count occurrences\n","day_df = df[\"InvoiceDate\"].dt.day_name().value_counts().reset_index()\n","day_df\n","\n","\n","import seaborn\n","\n","\n","# class v / s fare barplot with same colour\n","plt.figure(figsize=(13, 6))\n","sns.barplot(x = 'InvoiceDate', y = 'count', data = day_df, color = \"green\")\n","\n","# Show the plot\n","plt.show()\n"],"metadata":{"id":"kuRf4wtuphqN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"bbFf2-_FphqN"}},{"cell_type":"markdown","source":["Answer  - To check on which day customer has bought more products"],"metadata":{"id":"loh7H2nzphqN"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"_ouA3fa0phqN"}},{"cell_type":"markdown","source":["Answer - Customer is actively buying more goods on wednesday thursday and friday rest all the day"],"metadata":{"id":"VECbqPI7phqN"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"Seke61FWphqN"}},{"cell_type":"markdown","source":["Answer - Yes we can arrange special discount or offer on that particular day so that they will buy more items"],"metadata":{"id":"DW4_bGpfphqN"}},{"cell_type":"markdown","source":["#### Chart -  - Correlation Heatmap"],"metadata":{"id":"NC_X3p0fY2L0"}},{"cell_type":"code","source":["# Correlation Heatmap visualization code\n","\n","\n","\n","# Select only numeric columns for correlation calculation\n","numeric_df = df.select_dtypes(include='number')\n","\n","# Calculate the correlation matrix\n","correlation_matrix = numeric_df.corr()\n","\n","# Create the heatmap\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n","plt.title('Correlation Heatmap')\n","plt.show()\n"],"metadata":{"id":"xyC9zolEZNRQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"UV0SzAkaZNRQ"}},{"cell_type":"markdown","source":["Answer  -  To chek the co relation between the datas"],"metadata":{"id":"DVPuT8LYZNRQ"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"YPEH6qLeZNRQ"}},{"cell_type":"markdown","source":["Answer -  How the data perform when we co relate it means quantity and total spending has 0.39 co relation while there is no relation between customer id and total spending as it is obvoius by seeing the data also that it represent the customer id only"],"metadata":{"id":"bfSqtnDqZNRR"}},{"cell_type":"markdown","source":["## ***7. ML Model Implementation***"],"metadata":{"id":"VfCC591jGiD4"}},{"cell_type":"markdown","source":["### ML Model - 1"],"metadata":{"id":"OB4l2ZhMeS1U"}},{"cell_type":"markdown","source":["First creATING RFM customer segmentation and it is widely use in customer segmentation about how recently customer has frequently visit and purchased from our shop then i will distributed customer in 3 quartiles as per the answer i got First lets create RFM models"],"metadata":{"id":"eTMaC5um9Eou"}},{"cell_type":"markdown","source":["recencncy =  Last seen on our shop\n","\n","Frequency = how much they visit our shop\n","\n","Monetary = How much they bought from our shop"],"metadata":{"id":"cWNzQ6eCHcGX"}},{"cell_type":"code","source":["#Recency = Latest Date - Last Inovice Data, Frequency = count of invoice no. of transaction(s), Monetary = Sum of Total\n","#Amount for each customer\n","import datetime as dt\n","\n","#Set Latest date 2011-12-10 as last invoice date was 2011-12-09. This is to calculate the number of days from recent purchase\n","Latest_Date = dt.datetime(2011,12,10)\n","\n","#Create RFM Modelling scores for each customer\n","rfm_df = df.groupby('CustomerID').agg({'InvoiceDate': lambda x: (Latest_Date - x.max()).days, 'InvoiceNo': lambda x: len(x), 'TotalSpending': lambda x: x.sum()})\n","\n","#Convert Invoice Date into type int\n","rfm_df['InvoiceDate'] = rfm_df['InvoiceDate'].astype(int)\n","\n","#Rename column names to Recency, Frequency and Monetary\n","rfm_df.rename(columns={'InvoiceDate': 'Recency',\n","                         'InvoiceNo': 'Frequency',\n","                         'TotalSpending': 'Monetary'}, inplace=True)\n","\n","rfm_df.reset_index().head()"],"metadata":{"id":"SMpwg09g_Cm9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Descriptive Statistics (Recency)\n","rfm_df.Recency.describe()\n"],"metadata":{"id":"GtnxTrwBAjLg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Descriptive Statistics (Frequency)\n","rfm_df.Frequency.describe()"],"metadata":{"id":"FiF16sdlBdE-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Descriptive Statistics (Monetary)\n","rfm_df.Monetary.describe()"],"metadata":{"id":"uUWvDDXTBqi4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Split into four segments using quantiles**"],"metadata":{"id":"CKlIDSksH9E8"}},{"cell_type":"code","source":["#Split into four segments using quantiles\n","quantiles = rfm_df.quantile(q=[0.25,0.5,0.75])\n","quantiles = quantiles.to_dict()"],"metadata":{"id":"5UG1ABLiCHIy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["quantiles"],"metadata":{"id":"bGG8aCVMB9G1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Functions to create R, F and M segments\n","def RScoring(x,p,d):\n","    if x <= d[p][0.25]:\n","        return 1\n","    elif x <= d[p][0.50]:\n","        return 2\n","    elif x <= d[p][0.75]:\n","        return 3\n","    else:\n","        return 4\n","\n","def FnMScoring(x,p,d):\n","    if x <= d[p][0.25]:\n","        return 4\n","    elif x <= d[p][0.50]:\n","        return 3\n","    elif x <= d[p][0.75]:\n","        return 2\n","    else:\n","        return 1"],"metadata":{"id":"2Hl3XkRNCa9m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Calculate Add R, F and M segment value columns in the existing dataset to show R, F and M segment values\n","rfm_df['R'] = rfm_df['Recency'].apply(RScoring, args=('Recency',quantiles,))\n","rfm_df['F'] = rfm_df['Frequency'].apply(FnMScoring, args=('Frequency',quantiles,))\n","rfm_df['M'] = rfm_df['Monetary'].apply(FnMScoring, args=('Monetary',quantiles,))\n","rfm_df.head()"],"metadata":{"id":"RbmT6qpdCcxo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#Calculate and Add RFMGroup value column showing combined concatenated score of RFM\n","rfm_df['RFMGroup'] = rfm_df.R.map(str) + rfm_df.F.map(str) + rfm_df.M.map(str)\n","\n","#Calculate and Add RFMScore value column showing total sum of RFMGroup values\n","rfm_df['RFMScore'] = rfm_df[['R', 'F', 'M']].sum(axis = 1)\n","rfm_df.head()"],"metadata":{"id":"rle70JauCkzS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rfm_df.RFMScore.describe()"],"metadata":{"id":"ytlsfGv5EeRo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Handle negative and zero values so as to handle infinite numbers during log transformation\n","def handle_neg_n_zero(num):\n","    if num <= 0:\n","        return 1\n","    else:\n","        return num\n","#Apply handle_neg_n_zero function to Recency and Monetary columns\n","rfm_df['Recency'] = [handle_neg_n_zero(x) for x in rfm_df.Recency]\n","rfm_df['Monetary'] = [handle_neg_n_zero(x) for x in rfm_df.Monetary]\n","\n","#Perform Log transformation to bring data into normal or near normal distribution\n","Log_Tfd_Data = rfm_df[['Recency', 'Frequency', 'Monetary']].apply(np.log, axis = 1).round(3)"],"metadata":{"id":"GInUdvDwCsDP"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvE8gFQ3378L"},"source":["from sklearn import preprocessing\n","import math\n","rfm_df['Recency_log'] = rfm_df['Recency'].apply(math.log)\n","rfm_df['Frequency_log'] = rfm_df['Frequency'].apply(math.log)\n","rfm_df['Monetary_log'] = rfm_df['Monetary'].apply(math.log)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculation of Silhouette score and applying elbow method on Recency_log','Monetary_log  For ml model 1"],"metadata":{"id":"ocGQAuA3XnuN"}},{"cell_type":"code","source":["# ML Model - 1 Implementation\n","\n","# Fit the Algorithm\n","\n","# Predict on the model\n","\n","\n","from sklearn.metrics import silhouette_score\n","from sklearn.datasets import make_blobs\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_samples, silhouette_score\n","from sklearn.cluster import KMeans\n","features_rec_mon=['Recency_log','Monetary_log']\n","X_features_rec_mon=rfm_df[features_rec_mon].values\n","scaler_rec_mon=preprocessing.StandardScaler()\n","X_rec_mon=scaler_rec_mon.fit_transform(X_features_rec_mon)\n","X=X_rec_mon\n","range_n_clusters = [2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n","for n_clusters in range_n_clusters:\n","    clusterer = KMeans(n_clusters=n_clusters)\n","    preds = clusterer.fit_predict(X)\n","    centers = clusterer.cluster_centers_\n","\n","    score = silhouette_score(X, preds)\n","    print(\"For n_clusters = {}, silhouette score is {}\".format(n_clusters, score))\n","\n","\n"],"metadata":{"id":"7ebyywQieS1U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Applying the elbow method\n","\n","features_rec_mon=['Recency_log','Monetary_log']\n","X_features_rec_mon=rfm_df[features_rec_mon].values\n","scaler_rec_mon=preprocessing.StandardScaler()\n","X_rec_mon=scaler_rec_mon.fit_transform(X_features_rec_mon)\n","X=X_rec_mon\n","\n","from sklearn.cluster import KMeans\n","\n","sum_of_sq_dist = {}\n","for k in range(1,15):\n","    km = KMeans(n_clusters= k, init= 'k-means++', max_iter= 1000)\n","    km = km.fit(X)\n","    sum_of_sq_dist[k] = km.inertia_\n","\n","#Plot the graph for the sum of square distance values and Number of Clusters\n","sns.pointplot(x = list(sum_of_sq_dist.keys()), y = list(sum_of_sq_dist.values()))\n","plt.xlabel('Number of Clusters(k)')\n","plt.ylabel('Sum of Square Distances')\n","plt.title('Elbow Method For Optimal k')\n","plt.show()"],"metadata":{"id":"xK1_FAo9X2wP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","kmeans = KMeans(n_clusters=2)\n","kmeans.fit(X)\n","y_kmeans= kmeans.predict(X)"],"metadata":{"id":"NupxNcPZX9Aj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#lets determine the center\n","\n","plt.figure(figsize=(15,10))\n","plt.title('customer segmentation based on Recency and Monetary')\n","plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='spring')\n","\n","centers = kmeans.cluster_centers_\n","plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.5)"],"metadata":{"id":"TTPrNHgU_Yvr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Applying DBSCAN on Recency and Monetary"],"metadata":{"id":"wUruQEa2YNqf"}},{"cell_type":"code","source":["from sklearn.cluster import DBSCAN\n","from sklearn import metrics\n","y_pred = DBSCAN(eps=0.5, min_samples=15).fit_predict(X)\n","plt.figure(figsize=(13,8))\n","plt.scatter(X[:,0], X[:,1], c=y_pred)\n"],"metadata":{"id":"B1Fm07K2AQ1Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["DBSCAN does good as it removes the outliers as black dots and white as single clustering"],"metadata":{"id":"y5ijc6qTmQc1"}},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"ArJBuiUVfxKd"}},{"cell_type":"markdown","source":["As from the above 2 graph you can see the clear difference between elbow method and DBSCAN"],"metadata":{"id":"A1af_yQ2tNZX"}},{"cell_type":"markdown","source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."],"metadata":{"id":"TfvqoZmBfxKf"}},{"cell_type":"markdown","source":["DBSCAN does good job to remove outliers while keeping whole set of customer clusters together"],"metadata":{"id":"OaLui8CcfxKf"}},{"cell_type":"markdown","source":["### ML Model - 2"],"metadata":{"id":"dJ2tPlVmpsJ0"}},{"cell_type":"markdown","source":["Calculation of Silhouette score and applying elbow method on frequency_log','Monetary_log  For ml model 2"],"metadata":{"id":"vSB1EJemYnA3"}},{"cell_type":"code","source":["# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n","\n","# Fit the Algorithm\n","\n","# Predict on the model\n","\n","features_fre_mon=['Frequency_log','Monetary_log']\n","X_features_fre_mon=rfm_df[features_fre_mon].values\n","scaler_fre_mon=preprocessing.StandardScaler()\n","X_fre_mon=scaler_fre_mon.fit_transform(X_features_fre_mon)\n","X=X_fre_mon\n","range_n_clusters = [2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n","for n_clusters in range_n_clusters:\n","    clusterer = KMeans(n_clusters=n_clusters)\n","    preds = clusterer.fit_predict(X)\n","    centers = clusterer.cluster_centers_\n","\n","    score = silhouette_score(X, preds)\n","    print(\"For n_clusters = {}, silhouette score is {}\".format(n_clusters, score))\n"],"metadata":{"id":"Dn0EOfS6psJ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Aapplying the elbow method\n","\n","\n","from sklearn.cluster import KMeans\n","\n","sum_of_sq_dist = {}\n","for k in range(1,15):\n","    km = KMeans(n_clusters= k, init= 'k-means++', max_iter= 1000)\n","    km = km.fit(X)\n","    sum_of_sq_dist[k] = km.inertia_\n","\n","#Plot the graph for the sum of square distance values and Number of Clusters\n","sns.pointplot(x = list(sum_of_sq_dist.keys()), y = list(sum_of_sq_dist.values()))\n","plt.xlabel('Number of Clusters(k)')\n","plt.ylabel('Sum of Square Distances')\n","plt.title('Elbow Method For Optimal k')\n","plt.show()"],"metadata":{"id":"0RvNEVXeZEEI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["the elbow method show us 2 is the good value for K"],"metadata":{"id":"HBT_fivjqiTD"}},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","kmeans = KMeans(n_clusters=2)\n","kmeans.fit(X)\n","y_kmeans= kmeans.predict(X)"],"metadata":{"id":"8JiIY0RdZJjk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# centers\n","\n","\n","plt.figure(figsize=(15,10))\n","plt.title('customer segmentation based on   Frequency and Monetary')\n","plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='PiYG')\n","\n","centers = kmeans.cluster_centers_\n","plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.5)"],"metadata":{"id":"UCKlVMnxZKQH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Applying DBSCAN on frequency and Monetary"],"metadata":{"id":"oQkVx1DeZW3w"}},{"cell_type":"code","source":["from sklearn.cluster import DBSCAN\n","from sklearn import metrics\n","y_pred = DBSCAN(eps=0.5, min_samples=15).fit_predict(X)\n","plt.figure(figsize=(13,8))\n","plt.scatter(X[:,0], X[:,1], c=y_pred)"],"metadata":{"id":"3bTQhroiZaEv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."],"metadata":{"id":"zVGeBEFhpsJ2"}},{"cell_type":"markdown","source":["DBSCAN does good job to remove outliers while keeping whole set of customer clusters together"],"metadata":{"id":"74yRdG6UpsJ3"}},{"cell_type":"markdown","source":["#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."],"metadata":{"id":"bmKjuQ-FpsJ3"}},{"cell_type":"markdown","source":["Here we have used k means clustering algorithm and foe that we need the value of optimal k for that we have used two method like silhoutte score and elbow method from that we have select elbow methos and derived optimal no of clusters are 2 but that when we have applied DBSCAN method we can see a better chart instead of cluster them"],"metadata":{"id":"BDKtOrBQpsJ3"}},{"cell_type":"markdown","source":["### ML Model - 3"],"metadata":{"id":"Fze-IPXLpx6K"}},{"cell_type":"markdown","source":["Now using the dendogram"],"metadata":{"id":"ox4wfxvOaI9U"}},{"cell_type":"code","source":["# ML Model - 3 Implementation\n","\n","# Fit the Algorithm\n","\n","# Predict on the model\n","\n","import numpy as np\n","# Using the dendogram to find the optimal number of clusters\n","import scipy.cluster.hierarchy as sch\n","plt.figure(figsize=(20,8))\n","dendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\n","plt.title('Dendrogram')\n","plt.xlabel('Customers')\n","plt.ylabel('Euclidean Distances')\n","plt.show() # find largest vertical distance we can make without crossing any other horizontal line"],"metadata":{"id":"FFrSXAtrpx6M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"7AN1z2sKpx6M"}},{"cell_type":"markdown","source":["By using the dendogram we can see that there are 3 set of optimal cluster we can get using this data"],"metadata":{"id":"1ofZhgRbrjgA"}},{"cell_type":"markdown","source":["### 2. Which ML model did you choose from the above created models as your final prediction model and why?"],"metadata":{"id":"cBFFvTBNJzUa"}},{"cell_type":"markdown","source":["From above three I personally chosse the dendograms as it shows clearly that there are three customer segments in our data whom we can apply unsupervised machine learning properly"],"metadata":{"id":"6ksF5Q1LKTVm"}},{"cell_type":"markdown","source":["### 3. Explain the model which you have used and the feature importance using any model explainability tool?"],"metadata":{"id":"HvGl1hHyA_VK"}},{"cell_type":"markdown","source":["Here I have used two algorithms genrely\n","\n","1 - Kmeans clustering on recency ,frequency , monetary\n","\n","2 - Dendogram\n","\n","to cluster different types of customer groups"],"metadata":{"id":"YnvVTiIxBL-C"}},{"cell_type":"markdown","source":["### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"],"metadata":{"id":"-Kee-DAl2viO"}},{"cell_type":"markdown","source":["# **Conclusion**"],"metadata":{"id":"gCX9965dhzqZ"}},{"cell_type":"markdown","source":["# I think dendogram is the best plot where it can suggest us 3 cluster as per given data"],"metadata":{"id":"Fjb1IsQkh3yE"}},{"cell_type":"markdown","source":["### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"],"metadata":{"id":"gIfDvo9L0UH2"}}]}